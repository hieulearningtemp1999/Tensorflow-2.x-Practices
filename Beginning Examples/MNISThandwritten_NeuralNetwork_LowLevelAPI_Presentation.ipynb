{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7319602",
   "metadata": {},
   "source": [
    "### Descriptions:\n",
    "This notebook is for learning neural network in classification handwritten number in mnist dataset. Tensorflow should be used and the model is built on low-level api of tensorflow. Custom training loop is also taken with gradient tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12847bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5ac70",
   "metadata": {},
   "source": [
    "### Get mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c74475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train = np.array(x_train,dtype=np.float32)\n",
    "x_test = np.array(x_test,dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60a29d",
   "metadata": {},
   "source": [
    "## Normalize ,flatten input and one-hot coding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8bed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes = 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080b215",
   "metadata": {},
   "source": [
    "## Get dataset with batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c116928",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbabb46",
   "metadata": {},
   "source": [
    "## Build weights,biases -> model\n",
    "the model contains three dense layers , the first layer with shape 784x1024 , the second layer with 1024x10 nodes followed by the softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0386493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.initializers.HeNormal()\n",
    "weight_shapes = {\n",
    "    'w1': [784,1024],\n",
    "    'w2': [1024,10]\n",
    "}\n",
    "biases_shapes = {\n",
    "    'b1': [1024],\n",
    "    'b2': [10]\n",
    "}\n",
    "def get_trainable_params(shape,name):\n",
    "    return tf.Variable(initializer(shape),name=name,trainable=True,dtype=tf.float32)\n",
    "\n",
    "trainable_params = []\n",
    "trainable_params.append(get_trainable_params(weight_shapes['w1'],'w1'))\n",
    "trainable_params.append(get_trainable_params(biases_shapes['b1'],'b1'))\n",
    "trainable_params.append(get_trainable_params(weight_shapes['w2'],'w2'))\n",
    "trainable_params.append(get_trainable_params(biases_shapes['b2'],'b2'))\n",
    "\n",
    "def model(x):\n",
    "    # Reshape input from (batchsize,28,28) -> (batchsize,784)\n",
    "    x = tf.matmul(x,trainable_params[0])\n",
    "    x = tf.add(x,trainable_params[1])\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.nn.dropout(x,rate = 0.3)\n",
    "    \n",
    "    x = tf.matmul(x,trainable_params[2])\n",
    "    x = tf.add(x,trainable_params[3])\n",
    "    x = tf.nn.softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a2ad6",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42716be",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "def loss(pred,target):\n",
    "    return tf.reduce_mean(tf.losses.categorical_crossentropy(target,pred))\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41366f8",
   "metadata": {},
   "source": [
    "### Define train_step and test step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a94296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(data,target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(data)\n",
    "        train_loss = loss(pred,target)\n",
    "    grads = tape.gradient(train_loss,trainable_params)\n",
    "    optimizer.apply_gradients(zip(grads,trainable_params))\n",
    "    pred_label = tf.argmax(pred,axis=1)\n",
    "    target_label = tf.argmax(target,axis=1)\n",
    "    check_equal = (tf.cast(pred_label,tf.int64)) == (tf.cast(target_label,tf.int64))\n",
    "    correct = tf.reduce_sum(tf.cast(check_equal,tf.float32))\n",
    "    return train_loss,correct\n",
    "\n",
    "def test_step(data,target):\n",
    "    pred = model(data)\n",
    "    test_loss = loss(pred,target)\n",
    "    pred_label = tf.argmax(pred,axis=1)\n",
    "    target_label = tf.argmax(target,axis=1)\n",
    "    check_equal = (tf.cast(pred_label,tf.int64)) == (tf.cast(target_label,tf.int64))\n",
    "    correct = tf.reduce_sum(tf.cast(check_equal,tf.float32))\n",
    "    return test_loss,correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60732c2",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd622427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 46.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 126.70it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9563.0, shape=(), dtype=float32) tf.Tensor(55686.0, shape=(), dtype=float32)\n",
      "EPOCH : 1/10, train_loss : 0.2391355037689209,train_acc : 92.80999755859375, test_loss :0.13886849582195282, test_acc : 95.6300048828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 47.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.32it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9655.0, shape=(), dtype=float32) tf.Tensor(58065.0, shape=(), dtype=float32)\n",
      "EPOCH : 2/10, train_loss : 0.10584694147109985,train_acc : 96.7750015258789, test_loss :0.10322239995002747, test_acc : 96.55000305175781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.36it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9617.0, shape=(), dtype=float32) tf.Tensor(58637.0, shape=(), dtype=float32)\n",
      "EPOCH : 3/10, train_loss : 0.07251103222370148,train_acc : 97.72833251953125, test_loss :0.12267841398715973, test_acc : 96.17000579833984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.31it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9697.0, shape=(), dtype=float32) tf.Tensor(58946.0, shape=(), dtype=float32)\n",
      "EPOCH : 4/10, train_loss : 0.05555057153105736,train_acc : 98.24333190917969, test_loss :0.10273538529872894, test_acc : 96.97000122070312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.32it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9725.0, shape=(), dtype=float32) tf.Tensor(59174.0, shape=(), dtype=float32)\n",
      "EPOCH : 5/10, train_loss : 0.04254589229822159,train_acc : 98.62333679199219, test_loss :0.08969199657440186, test_acc : 97.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.69it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9754.0, shape=(), dtype=float32) tf.Tensor(59273.0, shape=(), dtype=float32)\n",
      "EPOCH : 6/10, train_loss : 0.03627990186214447,train_acc : 98.788330078125, test_loss :0.08902158588171005, test_acc : 97.53999328613281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.95it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9774.0, shape=(), dtype=float32) tf.Tensor(59358.0, shape=(), dtype=float32)\n",
      "EPOCH : 7/10, train_loss : 0.03129735589027405,train_acc : 98.93000030517578, test_loss :0.08183076977729797, test_acc : 97.73999786376953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 47.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 129.55it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9766.0, shape=(), dtype=float32) tf.Tensor(59484.0, shape=(), dtype=float32)\n",
      "EPOCH : 8/10, train_loss : 0.026197129860520363,train_acc : 99.13999938964844, test_loss :0.08678855746984482, test_acc : 97.65999603271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.37it/s]\n",
      "  0%|                                                                                          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9793.0, shape=(), dtype=float32) tf.Tensor(59493.0, shape=(), dtype=float32)\n",
      "EPOCH : 9/10, train_loss : 0.024779407307505608,train_acc : 99.1550064086914, test_loss :0.07878308743238449, test_acc : 97.93000030517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 47.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9766.0, shape=(), dtype=float32) tf.Tensor(59530.0, shape=(), dtype=float32)\n",
      "EPOCH : 10/10, train_loss : 0.02162688598036766,train_acc : 99.21666717529297, test_loss :0.08770375698804855, test_acc : 97.65999603271484\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    nums_train = 0 \n",
    "    nums_test = 0\n",
    "    train_corrects = 0 \n",
    "    test_corrects =0\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for data,target in tqdm(train_dataset):\n",
    "        train_loss,correct = train_step(data,target)\n",
    "        nums_train += len(data)\n",
    "        train_corrects += correct\n",
    "        train_losses.append(train_loss)\n",
    "#         break\n",
    "    \n",
    "    for data,target in tqdm(test_dataset):\n",
    "        test_loss,correct = test_step(data,target)\n",
    "        nums_test += len(data)\n",
    "        test_corrects += correct\n",
    "        test_losses.append(test_loss)\n",
    "#         break\n",
    "    print(test_corrects,train_corrects)\n",
    "    print(\"EPOCH : {}/{}, train_loss : {},train_acc : {}, test_loss :{}, test_acc : {}\".format(epoch+1,epochs,sum(train_losses)/len(train_losses),train_corrects/nums_train*100.,sum(test_losses)/len(test_losses),test_corrects/nums_test*100.))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f0876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
